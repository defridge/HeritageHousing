{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Building and Evaluation**\n",
    "\n",
    "## Objectives\n",
    "\n",
    "* **Business Requirement 2:**\n",
    "    * Develop a machine learning model to predict the sale price of Lydia's four inherited houses and any house in Ames, Iowa, with at least 75% accuracy.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* Main Dataset:\n",
    "    * 'outputs/datasets/collection/HousePricing.csv'\n",
    "    \n",
    "* Inherited Houses Dataset:\n",
    "    * 'outputs/datasets/collection/InheritedHouses.csv'\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* **Trained Models:** Linear Regression, Random Forest, XGBoost models trained to predict house prices.\n",
    "\n",
    "* **Predicted Sale Prices:** Predictions of house prices for Lydia's inherited houses using the trained models.\n",
    "\n",
    "* **Comparison Table:** A summary table comparing the performance of the three models based on R² and Mean Squared Error (MSE) on both training and testing datasets.\n",
    "\n",
    "* **CSV File with Predictions:** The predicted sale prices of the inherited houses saved to 'outputs/datasets/collection/inherited_houses_predictions.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python packages in the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r /workspace/HeritageHousing/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working directory\n",
    "\n",
    "Before starting we need to change to the correct directory (from where it is to its parent folder).\n",
    "\n",
    "We first access the current directory using os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below will confirm the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the main dataset and the inherited houses data and checking to make sure they load correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('outputs/datasets/collection/HousePricing.csv')\n",
    "inherited_houses = pd.read_csv('outputs/datasets/collection/InheritedHouses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Main Housing Dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInherited Houses Dataset:\")\n",
    "inherited_houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will handle missing values and ensure the data is in good shape for model training. We'll apply the same cleaning steps to both the main dataset and the inherited house dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for Missing Values**\n",
    "\n",
    "First, let's check for missing values in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in the main housing dataset:\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values in the inherited houses dataset:\")\n",
    "print(inherited_houses.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling Missing Values**\n",
    "\n",
    "Now that we have identified which columns have missing values, we will handle them based on the nature of each feature. We'll apply the same strategy we used earlier for the main dataset and inherited houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Handling Missing Values in Main Housing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 'EnclosedPorch' and 'WoodDeckSF', assume missing means the absence of those features. Fill with 0.\n",
    "df['EnclosedPorch'].fillna(0, inplace=True)\n",
    "df['WoodDeckSF'].fillna(0, inplace=True)\n",
    "\n",
    "# For 'LotFrontage', fill with the median value as it’s a critical numeric feature.\n",
    "df['LotFrontage'].fillna(df['LotFrontage'].median(), inplace=True)\n",
    "\n",
    "# For 'GarageFinish' and 'GarageYrBlt', assume missing means no garage. Fill with 'No Garage' and 0 respectively.\n",
    "df['GarageFinish'].fillna('No Garage', inplace=True)\n",
    "df['GarageYrBlt'].fillna(0, inplace=True)\n",
    "\n",
    "# For 'BsmtFinType1' and 'BsmtExposure', assume missing means no basement. Fill with 'No Basement' and 'No Exposure'.\n",
    "df['BsmtFinType1'].fillna('No Basement', inplace=True)\n",
    "df['BsmtExposure'].fillna('No Exposure', inplace=True)\n",
    "\n",
    "# For 'BedroomAbvGr', fill with the mode (most common number of bedrooms).\n",
    "df['BedroomAbvGr'].fillna(df['BedroomAbvGr'].mode()[0], inplace=True)\n",
    "\n",
    "# For '2ndFlrSF', assume missing means no second floor. Fill with 0.\n",
    "df['2ndFlrSF'].fillna(0, inplace=True)\n",
    "\n",
    "# For 'MasVnrArea', assume missing means no masonry veneer. Fill with 0.\n",
    "df['MasVnrArea'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Handling Missing Values in the Inherited Houses Dataset**\n",
    "\n",
    "We will use the same strategy for the inherited house data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for inherited houses in the same way\n",
    "inherited_houses['EnclosedPorch'].fillna(0, inplace=True)\n",
    "inherited_houses['WoodDeckSF'].fillna(0, inplace=True)\n",
    "inherited_houses['LotFrontage'].fillna(inherited_houses['LotFrontage'].median(), inplace=True)\n",
    "inherited_houses['GarageFinish'].fillna('No Garage', inplace=True)\n",
    "inherited_houses['GarageYrBlt'].fillna(0, inplace=True)\n",
    "inherited_houses['BsmtFinType1'].fillna('No Basement', inplace=True)\n",
    "inherited_houses['BsmtExposure'].fillna('No Exposure', inplace=True)\n",
    "inherited_houses['BedroomAbvGr'].fillna(inherited_houses['BedroomAbvGr'].mode()[0], inplace=True)\n",
    "inherited_houses['2ndFlrSF'].fillna(0, inplace=True)\n",
    "inherited_houses['MasVnrArea'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Check for Missing Values Again**\n",
    "\n",
    "After handling the missing values, it's a good practice to check again to make sure there are no remaining missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in the main housing dataset:\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values in the inherited houses dataset:\")\n",
    "print(inherited_houses.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "In this step, we'll create new features and transform categorical data into numerical data, preparing the dataset for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Creating New Features**\n",
    "\n",
    "Since we’ve already discussed that total square footage (TotalSF) is an important attribute, we’ll create that feature by summing up the square footage from the first floor, second floor, and basement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalSF'] = df['1stFlrSF'] + df['2ndFlrSF'] + df['TotalBsmtSF']\n",
    "inherited_houses['TotalSF'] = inherited_houses['1stFlrSF'] + inherited_houses['2ndFlrSF'] + inherited_houses['TotalBsmtSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['TotalSF', 'SalePrice']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_houses[['TotalSF']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Encoding Categorical Variables**\n",
    "\n",
    "We need to convert categorical variables into numeric ones for the machine learning algorithms to process them. Since the categories (like quality ratings) have an inherent order, we’ll use label encoding for categorical features such as BsmtExposure, BsmtFinType1, GarageFinish, and KitchenQual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define mappings for each categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_exposure_mapping = {'No': 0, 'Mn': 1, 'Av': 2, 'Gd': 3, 'No Exposure': 4}\n",
    "bsmt_fin_type_mapping = {'No Basement': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "garage_finish_mapping = {'No Garage': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "kitchen_qual_mapping = {'Fa': 0, 'TA': 1, 'Gd': 2, 'Ex': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the mappings to the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure'] = df['BsmtExposure'].map(bsmt_exposure_mapping)\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].map(bsmt_fin_type_mapping)\n",
    "df['GarageFinish'] = df['GarageFinish'].map(garage_finish_mapping)\n",
    "df['KitchenQual'] = df['KitchenQual'].map(kitchen_qual_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the mappings to the inherited houses dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_houses['BsmtExposure'] = inherited_houses['BsmtExposure'].map(bsmt_exposure_mapping)\n",
    "inherited_houses['BsmtFinType1'] = inherited_houses['BsmtFinType1'].map(bsmt_fin_type_mapping)\n",
    "inherited_houses['GarageFinish'] = inherited_houses['GarageFinish'].map(garage_finish_mapping)\n",
    "inherited_houses['KitchenQual'] = inherited_houses['KitchenQual'].map(kitchen_qual_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first few rows of the main dataset to verify the mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first few rows of the inherited houses dataset to verify the mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_houses[['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Final Check Before Model Building**\n",
    "\n",
    "Ensure there are no categorical variables left and confirm the data types of all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data types in the main dataset:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nData types in the inherited houses dataset:\")\n",
    "print(inherited_houses.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data\n",
    "\n",
    "In this step we will be splitting the main dataset into training and testing sets. The training set will be use to build the model, and the testing set will be used to evaluate its performance.\n",
    "\n",
    "We will split the data as follow:\n",
    "\n",
    "* **Training Set:** 80% of the data, used to train the model.\n",
    "\n",
    "* **Testing Set:** 20% of the data, used to test the models performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Define the Target and Features**\n",
    "\n",
    "We need to specify the target variable (SalePrice) and the features (all other columns, except SalePrice).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['SalePrice'])\n",
    "y = df['SalePrice']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Splitting the Data**\n",
    "\n",
    "We will use train_test_split from scikit-learn to split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training Features Shape:\", X_train.shape)\n",
    "print(\"Testing Features Shape:\", X_test.shape)\n",
    "print(\"Training Target Shape:\", y_train.shape)\n",
    "print(\"Testing Target Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Save the Test Data to .csv files**\n",
    "\n",
    "Before moving to model selection training we will save the training and test data to .csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('outputs/datasets/collection/X_train.csv', index=False)\n",
    "y_train.to_csv('outputs/datasets/collection/y_train.csv', index=False)\n",
    "\n",
    "X_test.to_csv('outputs/datasets/collection/X_test.csv', index=False)\n",
    "y_test.to_csv('outputs/datasets/collection/y_test.csv', index=False)\n",
    "\n",
    "inherited_houses.to_csv('outputs/datasets/collection/inherited_houses_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Training\n",
    "\n",
    "Now we will choose a machine learning model and train it using the training data. Given that we are working on a regression problem (predicting house prices), we will start with a basic model: Linear Regression. Afterwards we can look at more advanced models like Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Training a Linear Regression Model**\n",
    "\n",
    "Linear Regression is one of the simplest and most interpretable models making it a good starting point. We will use this for baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Linear Regression model from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train (fit) the model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model Coefficients:\", lr_model.coef_)\n",
    "print(\"Model Intercept:\", lr_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Evaluate the Model**\n",
    "\n",
    "After training the model we need to evaluate its performance on both the training and testing sets. We will use R² (coefficient of determination) and mean squared error (MSE) as the evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr_model.predict(X_train)\n",
    "y_test_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Training R²: {train_r2:.2f}\")\n",
    "print(f\"Training Mean Squared Error: {train_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Testing R²: {test_r2:.2f}\")\n",
    "print(f\"Testing Mean Squared Error: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing R² of 0.83 exceeds the performance criteria of at least 0.75, meaning that the model generalizes well to the unseen testing data. This indicates that the model is performing well both on the training and testing sets.\n",
    "\n",
    "The Mean Squared Error (MSE) of 1.27 billion shows some variability in predictions, but given that the R² score is strong, the model is likely capturing the overall relationships between house attributes and sale prices effectively.\n",
    "\n",
    "**Summary of Performance:**\n",
    "\n",
    "* Training R²: 0.80\n",
    "\n",
    "* Testing R²: 0.83\n",
    "\n",
    "* Performance Criteria: Met on both training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Predicting Prices for Inherited Houses**\n",
    "\n",
    "Now that the model is trained, we can use it to predict the sale prices of Lydia’s inherited houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the sale prices for the inherited houses using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_houses_predictions = lr_model.predict(inherited_houses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the predictions as a new column in the inherited houses dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_houses['Predicted_SalePrice'] = inherited_houses_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the inherited houses with predicted sale prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_houses[['TotalSF', 'Predicted_SalePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Advanced Models**\n",
    "\n",
    "The first step in optimization is to try more powerful models. We'll start by exploring two well-known algorithms:\n",
    "\n",
    "* Random Forest\n",
    "\n",
    "* XGBoost\n",
    "\n",
    "These models are often better at capturing complex patterns in data compared to Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Training a Random Forest Model**\n",
    "\n",
    "A Random Forest is an ensemble model that uses multiple decision trees to improve prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Random Forest Regressor from scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train (fit) the Random Forest model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "train_r2_rf = rf_model.score(X_train, y_train)\n",
    "print(f\"Training R² (Random Forest): {train_r2_rf:.2f}\")\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_r2_rf = rf_model.score(X_test, y_test)\n",
    "print(f\"Testing R² (Random Forest): {test_r2_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Training an XGBoost Model**\n",
    "\n",
    "XGBoost is another powerful ensemble model that often performs well in regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the XGBoost Regressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train (fit) the XGBoost model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "train_r2_xgb = xgb_model.score(X_train, y_train)\n",
    "print(f\"Training R² (XGBoost): {train_r2_xgb:.2f}\")\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_r2_xgb = xgb_model.score(X_test, y_test)\n",
    "print(f\"Testing R² (XGBoost): {test_r2_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Using Random Forest and XGBoost models on Inherited Houses Data to see if Hyperparameter tuning is needed**\n",
    "\n",
    "The results of the testing on the Training and Test datasets are as follow:\n",
    "\n",
    "* **Training R² (Random Forest): 0.98**\n",
    "\n",
    "* **Testing R² (Random Forest): 0.89**\n",
    "\n",
    "* **Training R² (XGBoost): 1.00**\n",
    "\n",
    "* **Testing R² (XGBoost): 0.90**\n",
    "\n",
    "Given that these scores exceed expectations we will run the Inherited Houses data through the models to check preformace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any columns that are not part of the original features used during training\n",
    "inherited_houses_for_prediction = inherited_houses[X_train.columns]\n",
    "\n",
    "# Verify that the columns match between the training data and the inherited houses data\n",
    "print(\"Inherited houses columns (after dropping extra columns):\", inherited_houses_for_prediction.columns)\n",
    "print(\"Training data columns:\", X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sale prices for the inherited houses using the Random Forest model\n",
    "inherited_houses_rf_predictions = rf_model.predict(inherited_houses_for_prediction)\n",
    "\n",
    "# Add the Random Forest predictions as a new column in the inherited houses dataset\n",
    "inherited_houses['Predicted_SalePrice_RF'] = inherited_houses_rf_predictions\n",
    "\n",
    "# Display the inherited houses with predicted sale prices using Random Forest\n",
    "print(\"Inherited Houses Predictions - Random Forest:\")\n",
    "inherited_houses[['TotalSF', 'Predicted_SalePrice_RF']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sale prices for the inherited houses using the XGBoost model\n",
    "inherited_houses_xgb_predictions = xgb_model.predict(inherited_houses_for_prediction)\n",
    "\n",
    "# Add the XGBoost predictions as a new column in the inherited houses dataset\n",
    "inherited_houses['Predicted_SalePrice_XGB'] = inherited_houses_xgb_predictions\n",
    "\n",
    "# Display the inherited houses with predicted sale prices using XGBoost\n",
    "print(\"Inherited Houses Predictions - XGBoost:\")\n",
    "inherited_houses[['TotalSF', 'Predicted_SalePrice_XGB']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "inherited_houses.to_csv('/workspace/HeritageHousing/outputs/datasets/collection/inherited_houses_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation & Comparison\n",
    "\n",
    "Now we will create a summary table comparing the performance of the Linear Regression, Random Forest, and XGBoost models on both the training and testing datasets. We will use the metrics R² and Mean Squared Error (MSE) for comparison.\n",
    "\n",
    "Steps to proceed:\n",
    "\n",
    "* Compute the R² and MSE for all models on both training and testing data.\n",
    "\n",
    "* Organize these results into a pandas DataFrame for easy comparison.\n",
    "\n",
    "* Display the table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "train_r2_lr = r2_score(y_train, y_train_pred)\n",
    "test_r2_lr = r2_score(y_test, y_test_pred)\n",
    "train_mse_lr = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Random Forest\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "train_mse_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "test_mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "\n",
    "# XGBoost\n",
    "y_train_pred_xgb = xgb_model.predict(X_train)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "train_r2_xgb = r2_score(y_train, y_train_pred_xgb)\n",
    "test_r2_xgb = r2_score(y_test, y_test_pred_xgb)\n",
    "train_mse_xgb = mean_squared_error(y_train, y_train_pred_xgb)\n",
    "test_mse_xgb = mean_squared_error(y_test, y_test_pred_xgb)\n",
    "\n",
    "# Print the R² and MSE for each model\n",
    "print(f\"Linear Regression - Training R²: {train_r2_lr:.2f}, Testing R²: {test_r2_lr:.2f}\")\n",
    "print(f\"Linear Regression - Training MSE: {train_mse_lr:.2f}, Testing MSE: {test_mse_lr:.2f}\\n\")\n",
    "\n",
    "print(f\"Random Forest - Training R²: {train_r2_rf:.2f}, Testing R²: {test_r2_rf:.2f}\")\n",
    "print(f\"Random Forest - Training MSE: {train_mse_rf:.2f}, Testing MSE: {test_mse_rf:.2f}\\n\")\n",
    "\n",
    "print(f\"XGBoost - Training R²: {train_r2_xgb:.2f}, Testing R²: {test_r2_xgb:.2f}\")\n",
    "print(f\"XGBoost - Training MSE: {train_mse_xgb:.2f}, Testing MSE: {test_mse_xgb:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Organize the Results into a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Training R²': [train_r2_lr, train_r2_rf, train_r2_xgb],\n",
    "    'Testing R²': [test_r2_lr, test_r2_rf, test_r2_xgb],\n",
    "    'Training MSE': [train_mse_lr, train_mse_rf, train_mse_xgb],\n",
    "    'Testing MSE': [test_mse_lr, test_mse_rf, test_mse_xgb]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "\n",
    "As we will be using the XGBoost model we will save it for later use so we dont have to retrain it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the 'outputs/models' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('outputs/models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to the specified path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_model, 'outputs/models/xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "results.plot(x='Model', y=['Training R²', 'Testing R²'], kind='bar', title='Model R² Comparison', figsize=(10,6))\n",
    "plt.ylabel('R² Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we achieved the following:\n",
    "\n",
    "### **Data Preparation:**\n",
    "- Cleaned the main and inherited house datasets by handling missing values and performing feature engineering (like creating the TotalSF feature).\n",
    "- Encoded categorical variables to numerical formats for use in machine learning models.\n",
    "\n",
    "### **Model Building and Evaluation:**\n",
    "- Trained three models: Linear Regression, Random Forest, and XGBoost.\n",
    "- Evaluated all models using R² and Mean Squared Error (MSE) on both training and testing datasets.\n",
    "- Generated predictions for Lydia’s inherited houses using all three models.\n",
    "\n",
    "### **Model Comparison:**\n",
    "- XGBoost outperformed the other models with the highest R² score on both training (0.999) and testing (0.897) sets, and the lowest MSE on the testing set.\n",
    "- Random Forest also performed well but had a slightly lower R² score on the testing set (0.887).\n",
    "- Linear Regression had the lowest performance in terms of R² and MSE.\n",
    "\n",
    "### **Final Model Selection:**\n",
    "Based on the comparison of models, **XGBoost** was selected as the best-performing model, as it generalizes well and provides the highest prediction accuracy for house prices. This model was saved for future use.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
